{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63326aa8-fbc5-4a8e-b036-780b25659716",
   "metadata": {},
   "source": [
    "# First-tier classifier to predict total cost class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09cc2e8-b215-426a-9947-a864e6cd7293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn import base\n",
    "from collections import defaultdict\n",
    "from matplotlib.ticker import FixedLocator, FixedFormatter\n",
    "from joblib import dump, load\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, \\\n",
    "RandomizedSearchCV, cross_val_score, RepeatedStratifiedKFold, KFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba449da-279c-4d45-b5b9-b635cab02b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data.xlsx\",sheet_name='Sheet1', usecols=\"A:AP\")\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6853188-1fa5-4825-b4ff-98ee35a48e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import category_encoders as ce\n",
    "X = df.drop(columns=['Total_loss_cost_classification_code'])\n",
    "y = df['Total_loss_cost_classification_code']\n",
    "encoder = ce.OrdinalEncoder(cols=['Construction_type_classification_code','Accident_type_code', 'Work_process_classification_code','Injury_area_classification_code','Workers_affiliation','Integrated_occupation_classification_code','Direct_insurance_cost_category_code'])\n",
    "X = encoder.fit_transform(X)\n",
    "X = encoder.transform(X)\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "# transform the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e24c91b-c8f0-4a46-9501-22ac146a377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2) #2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3375e3fe-5a89-4c39-bbe9-b772e95c0671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(clf, X_test=X_test, y_test=y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    r = permutation_importance(clf, X_test, y_test,\n",
    "                               n_repeats=30,\n",
    "                               random_state=0)\n",
    "    \n",
    "    for i in r.importances_mean.argsort()[::-1]:\n",
    "        print(f\"{X_test.columns[i]:<40} {r.importances_mean[i]:.4f} +/- {r.importances_std[i]:.4f}\")\n",
    "    \n",
    "    print(\"Mean cross-validated score of the best_estimator: {0:.3f}\".format(clf.best_score_))\n",
    "    print(\"Accuracy on train data: {0:.3f}\".format(clf.score(X_train, y_train)))\n",
    "    print(\"Accuracy on test data: {0:.3f}\".format(clf.score(X_test, y_test)))\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(\"Tuned Model Parameters: {}\".format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc9a43d-e01d-4293-b70f-e3cafb59e81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8218f2ab-cee3-4536-aa85-1185ca88a3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list={}\n",
    "param_grid = dict(\n",
    "    criterion=['gini', 'entropy'],\n",
    "    min_samples_split=[2, 10],\n",
    "    max_depth=[5, 6, 7, 8, 9],\n",
    "    min_samples_leaf=[1, 10],\n",
    "    max_leaf_nodes=[10, 20])\n",
    "dt_gscv = GridSearchCV(DecisionTreeClassifier(random_state=0), \n",
    "                       param_grid, scoring='accuracy')\n",
    "dt_gscv.fit(X_train, y_train)\n",
    "model_eval(dt_gscv)\n",
    "result_list['DT'] = dt_gscv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d2b422-995e-404c-84ce-5a323ceddaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "param_grid = dict(\n",
    "    criterion=['gini', 'entropy'],\n",
    "    min_samples_split=[8, 16, 20],\n",
    "    max_depth=[6, 8, 10, 12],\n",
    "    min_samples_leaf=[8, 12, 18],\n",
    "    max_leaf_nodes=[10, 20],\n",
    "    n_estimators=[10,100,200])\n",
    "rt_gscv = GridSearchCV(RandomForestClassifier(random_state=0), \n",
    "                       param_grid, scoring='accuracy')\n",
    "rt_gscv.fit(X_train, y_train)\n",
    "model_eval(rt_gscv)\n",
    "result_list['RF'] = rt_gscv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5354527f-b39e-4f4c-8379-0a459187e8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier()\n",
    "param_grid = {\n",
    "    'n_neighbors': [2,3, 5, 7, 9, 12, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "knn_gscv = GridSearchCV(knn_clf, param_grid=param_grid)\n",
    "knn_gscv.fit(X_train, y_train)\n",
    "model_eval(knn_gscv)\n",
    "result_list['KNN'] = knn_gscv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00948d0-d442-4d77-a774-a1857e800873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "params = {\n",
    "            'objective':'reg:logistic',\n",
    "            'max_depth': 4,\n",
    "            'alpha': 10,\n",
    "            'learning_rate': 0.01,\n",
    "            'n_estimators':100\n",
    "        }\n",
    "            \n",
    "            \n",
    "            \n",
    "# instantiate the classifier \n",
    "xgb_clf = XGBClassifier(**params,enable_categorical=True)\n",
    "\n",
    "\n",
    "\n",
    "# fit the classifier to the training data\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "# check accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('XGBoost model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(\"Accuracy on train data: {0:.3f}\".format(xgb_clf.score(X_train, y_train)))\n",
    "result_list['XGBoost'] = xgb_clf.score(X_test, y_test)\n",
    "r = permutation_importance(xgb_clf, X_test, y_test,\n",
    "                               n_repeats=30,\n",
    "                               random_state=0)\n",
    "    \n",
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "    print(f\"{X_test.columns[i]:<40} {r.importances_mean[i]:.4f} +/- {r.importances_std[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55e8db5-9586-4836-9a03-ddb62b788300",
   "metadata": {},
   "source": [
    "# Random Undersampling of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0978e3ce-e63c-4a23-8a46-331a405dbc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy='majority')\n",
    "rus.fit(X, y)\n",
    "X_resampled1, y_resampled1 = rus.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab7e440-b327-49a1-93ec-0ce64bbd10cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled1, y_resampled1, random_state=42, test_size=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309c7c80-3159-4f99-b045-27ac32f4766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, roc_curve\n",
    "def model_eval(clf, X_test=X_test, y_test=y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Mean cross-validated score of the best_estimator: {0:.3f}\".format(clf.best_score_))\n",
    "    print(\"Accuracy on train data: {0:.3f}\".format(clf.score(X_train, y_train)))\n",
    "    print(\"Accuracy on test data: {0:.3f}\".format(clf.score(X_test, y_test)))\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(\"Tuned Model Parameters: {}\".format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050ccd5a-741b-4127-85ba-ab558f3e749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list={}\n",
    "param_grid = dict(\n",
    "    criterion=['gini', 'entropy'],\n",
    "    min_samples_split=[2, 10],\n",
    "    max_depth=[5, 6, 7, 8, 9],\n",
    "    min_samples_leaf=[1, 10],\n",
    "    max_leaf_nodes=[10, 20])\n",
    "dt_gscv = GridSearchCV(DecisionTreeClassifier(random_state=0), \n",
    "                       param_grid, scoring='accuracy')\n",
    "dt_gscv.fit(X_train, y_train)\n",
    "model_eval(dt_gscv)\n",
    "result_list['DT'] = dt_gscv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6da06c4-2bd1-4147-a59a-1a039fe22279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "param_grid = dict(\n",
    "    criterion=['gini', 'entropy'],\n",
    "    min_samples_split=[2, 10],\n",
    "    max_depth=[5, 10],\n",
    "    min_samples_leaf=[1, 10],\n",
    "    max_leaf_nodes=[10, 20])\n",
    "rt_gscv = GridSearchCV(RandomForestClassifier(random_state=0), \n",
    "                       param_grid, scoring='accuracy')\n",
    "rt_gscv.fit(X_train, y_train)\n",
    "model_eval(rt_gscv)\n",
    "result_list['RF'] = rt_gscv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba6d3ae-4ce2-4ff8-8853-b75c38f436b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier()\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 12, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "knn_gscv = GridSearchCV(knn_clf, param_grid=param_grid)\n",
    "knn_gscv.fit(X_train, y_train)\n",
    "model_eval(knn_gscv)\n",
    "result_list['KNN'] = knn_gscv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff7bf69-2dd6-4db8-a55f-a1d48d821a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "params = {\n",
    "            'objective':'reg:logistic',\n",
    "            'max_depth': 4,\n",
    "            'alpha': 10,\n",
    "            'learning_rate': 1.0,\n",
    "            'n_estimators':100\n",
    "        }\n",
    "            \n",
    "            \n",
    "            \n",
    "# instantiate the classifier \n",
    "xgb_clf = XGBClassifier(**params,enable_categorical=True)\n",
    "\n",
    "\n",
    "\n",
    "# fit the classifier to the training data\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "# check accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('XGBoost model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(\"Accuracy on train data: {0:.3f}\".format(xgb_clf.score(X_train, y_train)))\n",
    "result_list['XGBoost'] = xgb_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d65aa5c-45d7-484a-b15c-93a43db1c3f8",
   "metadata": {},
   "source": [
    "# Random Oversampling of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6d7f2d-b708-437c-849a-d519f658c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "ros.fit(X, y)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88618205-e629-4734-ad0b-f84b8a8e45af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7611a8f8-fd0a-458b-8015-b3c911819f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, roc_curve\n",
    "def model_eval(clf, X_test=X_test, y_test=y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Mean cross-validated score of the best_estimator: {0:.3f}\".format(clf.best_score_))\n",
    "    print(\"Accuracy on train data: {0:.3f}\".format(clf.score(X_train, y_train)))\n",
    "    print(\"Accuracy on test data: {0:.3f}\".format(clf.score(X_test, y_test)))\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(\"Tuned Model Parameters: {}\".format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c01275-94e1-4691-957e-91d94d3dea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list={}\n",
    "param_grid = dict(\n",
    "    criterion=['gini', 'entropy'],\n",
    "    min_samples_split=[2, 10],\n",
    "    max_depth=[5, 6, 7, 8, 9],\n",
    "    min_samples_leaf=[1, 10],\n",
    "    max_leaf_nodes=[10, 20])\n",
    "dt_gscv = GridSearchCV(DecisionTreeClassifier(random_state=0), \n",
    "                       param_grid, scoring='accuracy')\n",
    "dt_gscv.fit(X_train, y_train)\n",
    "model_eval(dt_gscv)\n",
    "result_list['DT'] = dt_gscv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4923e77-d8ef-4bad-909e-665484c81b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "param_grid = dict(\n",
    "    criterion=['gini', 'entropy'],\n",
    "    min_samples_split=[2, 10],\n",
    "    max_depth=[5, 10],\n",
    "    min_samples_leaf=[1, 10],\n",
    "    max_leaf_nodes=[10, 20])\n",
    "rt_gscv = GridSearchCV(RandomForestClassifier(random_state=0), \n",
    "                       param_grid, scoring='accuracy')\n",
    "rt_gscv.fit(X_train, y_train)\n",
    "model_eval(rt_gscv)\n",
    "result_list['RF'] = rt_gscv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcf3075-4afc-4cbb-b2ac-5aeda0c36752",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier()\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 12, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "knn_gscv = GridSearchCV(knn_clf, param_grid=param_grid)\n",
    "knn_gscv.fit(X_train, y_train)\n",
    "model_eval(knn_gscv)\n",
    "result_list['KNN'] = knn_gscv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30039e74-12b1-4536-830a-84cbe90a5251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "params = {\n",
    "            'objective':'reg:logistic',\n",
    "            'max_depth': 4,\n",
    "            'alpha': 10,\n",
    "            'learning_rate': 1.0,\n",
    "            'n_estimators':100\n",
    "        }\n",
    "            \n",
    "            \n",
    "            \n",
    "# instantiate the classifier \n",
    "xgb_clf = XGBClassifier(**params,enable_categorical=True)\n",
    "\n",
    "\n",
    "\n",
    "# fit the classifier to the training data\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "# check accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('XGBoost model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba61f073-7c4f-4be0-a82b-c740dcf5ccc6",
   "metadata": {},
   "source": [
    "# Second-tier regressor to predict indirect cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a40ac8-3230-4629-99a8-5ab8517763da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding\n",
    "categorical_cols = ['Direct_insurance_cost_total_category_code','Total_loss_cost_classification_code']\n",
    "numerical_cols = ['Human_damage_death','Human_damage_injuries','Direct_insurance_costs']\n",
    "target_col = 'Indirect_insurance_costs'\n",
    "X = df[categorical_cols + numerical_cols]\n",
    "y = df[target_col]\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import category_encoders as ce\n",
    "\n",
    "encoder = ce.OrdinalEncoder(cols=['Total_loss_cost_classification_code','Direct_insurance_cost_total_category_code'])\n",
    "X = encoder.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bccff68-7edd-4be8-a9eb-efbd53ad0c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc44788-df3e-4924-9d70-d54776cb3346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "ss_X = StandardScaler()\n",
    "ss_y = StandardScaler()\n",
    "\n",
    "X_train = ss_X.fit_transform(X_train)\n",
    "X_test = ss_X.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ade3ab-5033-46e1-92b4-7ba46dc83d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "regressor = DecisionTreeRegressor(random_state=42)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply TransformedTargetRegressor\n",
    "model = TransformedTargetRegressor(regressor=regressor, transformer=QuantileTransformer(output_distribution='normal'))\n",
    "\n",
    "# Fit and predict\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"R² score:\", r2_score(y_test, y_pred))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "result = permutation_importance(model, X_test, y_test, n_repeats=30, random_state=0)\n",
    "\n",
    "# Display importances\n",
    "for i in result.importances_mean.argsort()[::-1]:\n",
    "    print(f\"{X.columns[i]:<30} {result.importances_mean[i]:.4f} +/- {result.importances_std[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c61517d-aeb2-4cb6-900a-9d6bb0585b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Decalring numpy array variable\n",
    "\n",
    "xAxis = np.arange(y_pred.shape[0])\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.title(\"Decision Tree Regressor Result\")\n",
    "plt.xlabel(\"Test sample\")\n",
    "plt.ylabel(\"Indirect cost (US$)\")\n",
    "plt.plot(xAxis, y_pred, color =\"red\")\n",
    "plt.plot(xAxis, y_test, color =\"black\",linestyle='dotted')\n",
    "plt.legend(['prediction', 'actual']);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456e7d46-a911-488c-b564-78df5ddc64d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import lightgbm as lgbm\n",
    "import xgboost as xg\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "regr_trans = TransformedTargetRegressor(regressor=lgbm.LGBMRegressor(), transformer=QuantileTransformer(output_distribution='normal'))\n",
    "regr_trans.fit(X_train, y_train)\n",
    "yhat = regr_trans.predict(X_test)\n",
    "print(round(r2_score(y_test, yhat),3), round(mean_absolute_error(y_test, yhat),2), round(np.sqrt(mean_squared_error(y_test, yhat)),2))\n",
    "result = permutation_importance(regr_trans, X_test, y_test, n_repeats=30, random_state=0)\n",
    "\n",
    "# Display importances\n",
    "for i in result.importances_mean.argsort()[::-1]:\n",
    "    print(f\"{X.columns[i]:<30} {result.importances_mean[i]:.4f} +/- {result.importances_std[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7efaee-0e50-498f-8cf4-dd65705b8f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Decalring numpy array variable\n",
    "\n",
    "xAxis = np.arange(yhat.shape[0])\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.title(\"LGBM Regressor Result\")\n",
    "plt.xlabel(\"Test sample\")\n",
    "plt.ylabel(\"Indirect cost (US$)\")\n",
    "plt.plot(xAxis, yhat, color =\"red\")\n",
    "plt.plot(xAxis, y_test, color =\"black\",linestyle='dotted')\n",
    "plt.legend(['prediction', 'actual']);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51da1ba-fede-4a85-be76-76c036042745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import lightgbm as lgbm\n",
    "import xgboost as xg\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "regr_trans = TransformedTargetRegressor(regressor=GradientBoostingRegressor(), transformer=QuantileTransformer(output_distribution='normal'))\n",
    "regr_trans.fit(X_train, y_train)\n",
    "yhat = regr_trans.predict(X_test)\n",
    "print(round(r2_score(y_test, yhat),3), round(mean_absolute_error(y_test, yhat),2), round(np.sqrt(mean_squared_error(y_test, yhat)),2))\n",
    "result = permutation_importance(regr_trans, X_test, y_test, n_repeats=30, random_state=0)\n",
    "\n",
    "# Display importances\n",
    "for i in result.importances_mean.argsort()[::-1]:\n",
    "    print(f\"{X.columns[i]:<30} {result.importances_mean[i]:.4f} +/- {result.importances_std[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a47208-a03f-4546-a578-03c7db3c98d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Decalring numpy array variable\n",
    "\n",
    "xAxis = np.arange(yhat.shape[0])\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.title(\"GB Regressor Result\")\n",
    "plt.xlabel(\"Test sample\")\n",
    "plt.ylabel(\"Indirect cost (US$)\")\n",
    "plt.plot(xAxis, yhat, color =\"red\")\n",
    "plt.plot(xAxis, y_test, color =\"black\",linestyle='dotted')\n",
    "plt.legend(['prediction', 'actual']);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e08156-dcc6-4e05-b49f-c1d0fc4ebee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "## Define Grid \n",
    "model = RandomForestRegressor()\n",
    "#transforming target variable through quantile transformer\n",
    "ttr = TransformedTargetRegressor(regressor=model, transformer=QuantileTransformer(output_distribution='normal'))\n",
    "ttr.fit(X_train, y_train)\n",
    "yhat = ttr.predict(X_test)\n",
    "print(r2_score(y_test, yhat), mean_absolute_error(y_test, yhat), np.sqrt(mean_squared_error(y_test, yhat)))\n",
    "result = permutation_importance(ttr, X_test, y_test, n_repeats=30, random_state=0)\n",
    "\n",
    "# Display importances\n",
    "for i in result.importances_mean.argsort()[::-1]:\n",
    "    print(f\"{X.columns[i]:<30} {result.importances_mean[i]:.4f} +/- {result.importances_std[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11970874-110e-40b8-92fa-b3cc9a544359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Decalring numpy array variable\n",
    "\n",
    "xAxis = np.arange(yhat.shape[0])\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.title(\"RF Regressor Result\")\n",
    "plt.xlabel(\"Test sample\")\n",
    "plt.ylabel(\"Indirect cost (US$)\")\n",
    "plt.plot(xAxis, yhat, color =\"red\")\n",
    "plt.plot(xAxis, y_test, color =\"black\",linestyle='dotted')\n",
    "plt.legend(['prediction', 'actual']);\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML)yenv)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
